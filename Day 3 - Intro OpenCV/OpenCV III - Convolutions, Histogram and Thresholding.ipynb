{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - What are image convolutions?\n",
    "\n",
    "Basically, the process of convolution in images is an *element-wise multiplication of two matrices followed by a sum* [1]. The main idea follows these three steps:\n",
    "\n",
    "<ol>\n",
    "    <li>Take two matrices (which both have the same dimensions).</li>\n",
    "    <li>Multiply them, element-by-element (i.e., not the dot product, just a simple multiplication).</li>\n",
    "    <li>Sum the elements together.</li>\n",
    "</ol>\n",
    "\n",
    "# 2 - What are these matrices? \n",
    "\n",
    "To understand the meaning of the matrices, we can make an analogy of ``Big Matrix`` and ``Tiny Matrix``, being the ``Big Matrix`` is an image and the ``Tiny Matrix`` is the kernel. The center of the kernel should be positioned at the top left of the image, also slide from left to right and top to bottom, applying a mathematical operation (i.e., a convolution) at each (x, y)-coordinate of the original image.\n",
    "\n",
    "<center>\n",
    "    <figure style=\"margin-top:20px\">\n",
    "        <img src=\"images/kernel.png\" width=\"300\">\n",
    "        <figcaption style=\"margin-top:20px\">Figura 1 - Kernel sliding from left to right and up to bottom over the  ``Big Matrix`` [1].</figcaption>\n",
    "    </figure>\n",
    "</center>\n",
    "\n",
    "Now we already know the base of convolution and the meaning of kernels, some questions may appear, like: \n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "        <b>What is the purpose of the convolution?</b><br/>\n",
    "        Produce a new image based on pre-defined kernel and the ``Big Matrix``, where this new image has the same dimension that ``Big Matrix``. \n",
    "    </li>\n",
    "    <li>\n",
    "        <b>What will we gain with that technique?</b><br/>\n",
    "        With this tool, we win several ''filters\", as blurring and sharpening, also an important aid for edge detections, noise removal, etc.  \n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<center>\n",
    "    <figure style=\"margin-top:20px\">\n",
    "        <img src=\"images/examples.png\" width=\"500\">\n",
    "        <figcaption style=\"margin-top:20px\">Figura 2 - Examples of convolutions [1].</figcaption>\n",
    "    </figure>\n",
    "</center>\n",
    "\n",
    "For more informations about kernels and convolution, look the references [2] [3]. \n",
    "\n",
    "# 3 - Implementation\n",
    "\n",
    "To implement a convolution, we can follow the following steps:\n",
    "\n",
    "<ol>\n",
    "    <li>Obtain an input image.</li>\n",
    "    <li>Obtain a kernel matrix that we are going to apply to the input image.</li>\n",
    "    <li>Create an output image to store the output of the image convolved with the kernel.</li>\n",
    "    <li>\n",
    "        For each pixel of input image, do:\n",
    "        <ol>\n",
    "            <li>Select an (x, y)-coordinate from the original image.</li>\n",
    "            <li>Place the center of the kernel at this (x, y)-coordinate.</li>\n",
    "            <li>Take the element-wise multiplication of the input image region and the kernel, then sum\n",
    "    up the values of these multiplication operations into a single value. The sum of these\n",
    "    multiplications is called the kernel output.</li>\n",
    "            <li>Use the same (x, y)-coordinates from step A, but this time, store the kernel output at the\n",
    "    same (x, y)-location as the output image.</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Let's start coding.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing OpenCV, Numpy and pyplot\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.exposure import rescale_intensity as rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to convolve images\n",
    "def convolve(img, kernel):\n",
    "    # Obtaining the shape of matrices\n",
    "    i_rows, i_cols = img.shape[:2]\n",
    "    k_rows, k_cols = kernel.shape[:2]\n",
    "    \n",
    "    # Discovering how many pixels is needed to surround the image\n",
    "    pad_r = k_rows // 2\n",
    "    pad_c = k_cols // 2\n",
    "    \n",
    "    output = np.zeros((i_rows,i_cols), dtype='float')\n",
    "    \n",
    "    img = cv2.copyMakeBorder(img, pad_r, pad_r, pad_c, pad_c, cv2.BORDER_CONSTANT)\n",
    "        \n",
    "    for i in range(0, i_rows):\n",
    "        for j in range(0, i_cols):            \n",
    "            # Creating a window of same width and height of kernel\n",
    "            crop = img[i : i + (pad_r * 2) + 1, j : j + (pad_c * 2) + 1]\n",
    "            \n",
    "            # Applying product operation\n",
    "            result = (crop * kernel).sum()\n",
    "                        \n",
    "            # Storing the result\n",
    "            output[i,j] = result\n",
    "            \n",
    "    output = rescale(output, in_range=(0, 255))\n",
    "    output = (output * 255).astype(\"uint8\")\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Kernels\n",
    "\n",
    "Before we start our tests, let's define some kernels:\n",
    "\n",
    "<table style=\"float:left;margin-left:150px\">\n",
    "    <tr>\n",
    "        <th>Operation</th>\n",
    "        <th>Kernel</th>\n",
    "        <th>Image</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Identity</td>\n",
    "        <td>\n",
    "            $$\\begin{matrix}\n",
    "             0 & 0 & 0 \\\\\n",
    "             0 & 1 & 0 \\\\\n",
    "             0 & 0 & 0\n",
    "             \\end{matrix}$$\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"https://upload.wikimedia.org/wikipedia/commons/5/50/Vd-Orig.png\" width=\"100\">\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Sobel X</td>\n",
    "        <td>\n",
    "            $$\\begin{matrix}\n",
    "             -1 & 0 & 1 \\\\\n",
    "             -2 & 0 & 2 \\\\\n",
    "             -1 & 0 & 1\n",
    "             \\end{matrix}$$\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"https://upload.wikimedia.org/wikipedia/commons/8/8d/Vd-Edge1.png\" width=\"100\">\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Sobel Y</td>\n",
    "        <td>\n",
    "            $$\\begin{matrix}\n",
    "             -1 & -2 & -1 \\\\\n",
    "             0 & 0 & 0 \\\\\n",
    "             1 & 2 & 1\n",
    "             \\end{matrix}$$\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"https://upload.wikimedia.org/wikipedia/commons/8/83/Vd-Edge2.png\" width=\"100\">\n",
    "        </td>\n",
    "    </tr>    \n",
    "    <tr>\n",
    "        <td>Laplacian</td>\n",
    "        <td>\n",
    "            $$\\begin{matrix}\n",
    "             0 & 1 & 0 \\\\\n",
    "             1 & -4 & 1 \\\\\n",
    "             0 & 1 & 0\n",
    "             \\end{matrix}$$\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"images/laplacian.jpg\" width=\"100\">\n",
    "        </td>\n",
    "    </tr>\n",
    "</table> \n",
    "\n",
    "<table style=\"float:right;margin-right:150px\">\n",
    "    <tr>\n",
    "        <th>Operation</th>\n",
    "        <th>Kernel</th>\n",
    "        <th>Image</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Emboss</td>\n",
    "        <td>\n",
    "            $$\\begin{matrix}\n",
    "             -2 & -1 & 0 \\\\\n",
    "             -1 & 1 & 1 \\\\\n",
    "             0 & 1 & 2\n",
    "             \\end{matrix}$$\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"images/emboss.jpg\" width=\"100\">\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Sharpen</td>\n",
    "        <td>\n",
    "            $$\\begin{matrix}\n",
    "             0 & -1 & 0 \\\\\n",
    "             -1 & 5 & -1 \\\\\n",
    "             0 & -1 & 0\n",
    "             \\end{matrix}$$\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"https://upload.wikimedia.org/wikipedia/commons/4/4e/Vd-Sharp.png\" width=\"100\">\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Blur</td>\n",
    "        <td>\n",
    "            $$\\begin{matrix}\n",
    "             \\frac{1}{9} & \\frac{1}{9} & \\frac{1}{9} \\\\\n",
    "             \\frac{1}{9} & \\frac{1}{9} & \\frac{1}{9} \\\\\n",
    "             \\frac{1}{9} & \\frac{1}{9} & \\frac{1}{9}\n",
    "             \\end{matrix}$$\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"https://upload.wikimedia.org/wikipedia/commons/0/04/Vd-Blur2.png\" width=\"100\">\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Gaussian Blur</td>\n",
    "        <td>\n",
    "            $$\\begin{matrix}\n",
    "             1 & 2 & 1 \\\\\n",
    "             2 & 4 & 2 \\\\\n",
    "             1 & 2 & 1\n",
    "             \\end{matrix}$$\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"images/gaussian.jpg\" width=\"100\">\n",
    "        </td>\n",
    "    </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = np.array(([0, 0, 0],\n",
    "                     [0, 1, 0],\n",
    "                     [0, 0, 0]), dtype=\"int\")\n",
    "\n",
    "sobelX = np.array(([-1, 0, 1],\n",
    "                   [-2, 0, 2],\n",
    "                   [-1, 0, 1]), dtype=\"int\")\n",
    "\n",
    "sobelY = np.array(([-1, -2, -1],\n",
    "                   [0, 0, 0],\n",
    "                   [1, 2, 1]), dtype=\"int\")\n",
    "\n",
    "sharpen = np.array(([0, -1, 0],\n",
    "                    [-1, 5, -1],\n",
    "                    [0, -1, 0]), dtype=\"int\")\n",
    "\n",
    "blur = np.ones((3,3), dtype='float') / 9\n",
    "\n",
    "laplacian = np.array(([0, 1, 0],\n",
    "                      [1, -4, 1],\n",
    "                      [0, 1, 0]), dtype=\"int\")\n",
    "\n",
    "emboss = np.array(([-2, -1, 0],\n",
    "                   [-1, 1, 1],\n",
    "                   [0, 1, 2]), dtype=\"int\")\n",
    "\n",
    "gaussian = np.array(([1, 4, 1],\n",
    "                     [2, 4, 2],\n",
    "                     [1, 2, 1]), dtype=\"float\") / 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Let's test.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retina = cv2.imread('images/retina.jpg', 0)\n",
    "\n",
    "# Shape of image\n",
    "rows, cols = retina.shape\n",
    "\n",
    "# Scale factor\n",
    "scale = 0.5\n",
    "\n",
    "# Scaled image\n",
    "retina = cv2.resize(retina, (round(scale * cols), round(scale * rows)))\n",
    "\n",
    "result_identity = convolve(retina, identity)\n",
    "result_sobelx = convolve(retina, sobelX)\n",
    "result_sobely = convolve(retina, sobelY)\n",
    "result_sharpen = convolve(retina, sharpen)\n",
    "result_blur = convolve(retina, blur)\n",
    "result_laplacian = convolve(retina, laplacian)\n",
    "result_emboss = convolve(retina,emboss)\n",
    "result_gaussian = convolve(retina,gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing our results\n",
    "f, axarr = plt.subplots(2,4, figsize=(30,10))\n",
    "axarr[0,0].imshow(result_identity, cmap='gray')\n",
    "axarr[0,1].imshow(result_sobelx, cmap='gray')\n",
    "axarr[0,2].imshow(result_sobely, cmap='gray')\n",
    "axarr[0,3].imshow(result_laplacian, cmap='gray')\n",
    "axarr[1,0].imshow(result_emboss, cmap='gray')\n",
    "axarr[1,1].imshow(result_sharpen, cmap='gray')\n",
    "axarr[1,2].imshow(result_blur, cmap='gray')\n",
    "axarr[1,3].imshow(result_gaussian, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Using OpenCV's own functions\n",
    "\n",
    "Until now, we saw how to create convolution function, but OpenCV has its own functions to perform these operations. So, it is the moment to get to know some of these functions.\n",
    "\n",
    "### 3.2.1) Filter2D\n",
    "\n",
    "This function has the responsibility of convolving images, like our <b>convolve</b>. \n",
    "\n",
    "<center>\n",
    "    <strong>cv2.filter2D(src, ddepth, kernel[, dst[, anchor[, delta[, borderType]]]]) → dst</strong>\n",
    "</center>\n",
    "\n",
    "where:\n",
    "\n",
    "<ul>\n",
    "    <li><i>src</i> – The image</li>\n",
    "    <li><i>ddepth</i> – Desired depth of the destination image; if it is negative, it will be the same as src.depth(); the following combinations of src.depth() and ddepth are supported:\n",
    "        <ul>\n",
    "            <li>src.depth() = CV_8U, ddepth = -1/CV_16S/CV_32F/CV_64F</li>\n",
    "            <li>src.depth() = CV_16U/CV_16S, ddepth = -1/CV_32F/CV_64F</li>\n",
    "            <li>src.depth() = CV_32F, ddepth = -1/CV_32F/CV_64F</li>\n",
    "            <li>src.depth() = CV_64F, ddepth = -1/CV_64F</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><i>kernel</i> – Convolution kernel (or rather a correlation kernel), a single-channel floating point matrix; if you want to apply different kernels to different channels, split the image into separate color planes using split() and process them individually.</li>\n",
    "    <li><i>dst</i> – Output image of the same size and the same number of channels as img.</li>\n",
    "    <li><i>anchor</i> – Anchor of the kernel that indicates the relative position of a filtered point within the kernel; the anchor should lie within the kernel; default value (-1,-1) means that the anchor is at the kernel center.</li>\n",
    "    <li><i>delta</i> – Optional value added to the filtered pixels before storing them in dst.</li>\n",
    "    <li><i>borderType</i> – Pixel extrapolation method.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter2D = cv2.filter2D(retina, -1, emboss)\n",
    "\n",
    "# Comparative between convolve and filter2D\n",
    "plt.figure()\n",
    "plt.title(\"Image convolved by the convolve function\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(result_emboss, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Image convolved by the filter2D function\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(filter2D, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2) Blur's filters\n",
    "\n",
    "Here we have 3 functions, that have the responsibility of blurring images, like our <b>convolve</b> with kernel *Blur* and *Gaussian Blur*. \n",
    "\n",
    "<center>\n",
    "    <strong>cv2.blur(src, ksize[, dst[, anchor[, borderType]]]) → dst</strong><br />\n",
    "    <strong>cv2.GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY[, borderType]]])  → dst</strong><br />\n",
    "    <strong>cv2.medianBlur(src, ksize[, dst]) → dst</strong><br />\n",
    "</center>\n",
    "\n",
    "where:\n",
    "\n",
    "<ul>\n",
    "    <li><i>src</i> – The image</li>\n",
    "    <li><i>ksize</i> – (**Blur**) blurring kernel size. (**Gaussian**) Gaussian kernel size. ksize.width and ksize.height can differ but they both must be positive and odd. Or, they can be zero’s and then they are computed from sigma*. (**Median**) Aperture linear size; it must be odd and greater than 1, for example: 3, 5, 7, etc.</li>\n",
    "    <li><i>dst</i> – Output image of the same size and the same number of channels as img.</li>\n",
    "    <li><i>anchor</i> – Achor point; default value Point(-1,-1) means that the anchor is at the kernel center. The anchor should lie within the kernel; default value (-1,-1) means that the anchor is at the kernel center.</li>\n",
    "    <li><i>delta</i> – Optional value added to the filtered pixels before storing them in dst.</li>\n",
    "    <li><i>borderType</i> – Border mode used to extrapolate pixels outside of the image.</li>\n",
    "    <li><i>sigmaX</i> – Gaussian kernel standard deviation in X direction.</li>\n",
    "    <li><i>sigmaY</i> – Gaussian kernel standard deviation in Y direction. If sigmaY is zero, it is set to be equal to sigmaX, if both sigmas are zeros, they are computed from ksize.width and ksize.height , respectively to fully control the result regardless of possible future modifications of all this semantics, it is recommended to specify all of ksize, sigmaX, and sigmaY.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.blur(retina, (3,3))\n",
    "g_blurred = cv2.GaussianBlur(retina, (3,3), 0)\n",
    "m_blurred = cv2.medianBlur(retina, 3)\n",
    "\n",
    "# Comparative results\n",
    "plt.figure()\n",
    "plt.title(\"Image convolved by the convolve function\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(result_blur, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Image convolved by the blur function\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(blurred, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Image convolved by the convolve function\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(result_gaussian, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Image convolved by the GaussianBlur function\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(g_blurred, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Image convolved by the medianBlur function\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(m_blurred, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3) Laplacian filters\n",
    "\n",
    "This function calculates the laplacian of an image. \n",
    "\n",
    "<center>\n",
    "    <strong>cv2.Laplacian(src, ddepth[, dst[, ksize[, scale[, delta[, borderType]]]]]) → dst</strong><br />\n",
    "</center>\n",
    "\n",
    "where:\n",
    "\n",
    "<ul>\n",
    "    <li><i>src</i> – The image</li>\n",
    "    <li><i>ddepth</i> – Desired depth of the destination image.</li>\n",
    "    <li><i>dst</i> – Output image of the same size and the same number of channels as img.</li>\n",
    "    <li><i>ksize</i> – Aperture size used to compute the second-derivative filters. The size must be positive and odd.</li>\n",
    "    <li><i>scale</i> – Optional scale factor for the computed Laplacian values. By default, no scaling is applied. </li>\n",
    "    <li><i>delta</i> – Optional delta value that is added to the results prior to storing them in dst .</li>\n",
    "    <li><i>borderType</i> – Border mode used to extrapolate pixels outside of the image.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian_ex = cv2.Laplacian(retina, -1)\n",
    "\n",
    "# Comparative between convolve and filter2D\n",
    "plt.figure()\n",
    "plt.title(\"Image convolved by the convolve function\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(result_laplacian, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Image convolved by the laplacian function\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(laplacian_ex, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To see more functions of filter, look for the reference [4]*.\n",
    "\n",
    "# 4 - Histogram\n",
    "\n",
    "A histogram represents the distribution of pixel intensities (whether color or grayscale) in an image [5]. The use of histograms may help us to get know several informations about our images, like **contrast, brightness** and **intensity**.\n",
    "\n",
    "In OpenCV, we have the following function to calculate histograms: \n",
    "\n",
    "<center>\n",
    "    <strong>cv2.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]]) → hist</strong><br />\n",
    "</center>\n",
    "\n",
    "where:\n",
    "\n",
    "<ul>\n",
    "    <li><i>images</i> – Source arrays. They all should have the same depth, CV_8U or CV_32F , and the same size. Each of them can have an arbitrary number of channels.</li>\n",
    "    <li><i>channels</i> – List of the dims channels used to compute the histogram. The first array channels are numerated from 0 to images[0].channels()-1 , the second array channels are counted from images[0].channels() to images[0].channels() + images[1].channels()-1, and so on.</li>\n",
    "    <li><i>mask</i> – Optional mask. If the matrix is not empty, it must be an 8-bit array of the same size as images[i] . The non-zero mask elements mark the array elements counted in the histogram.</li>\n",
    "    <li><i>histSize</i> – Array of histogram sizes in each dimension.</li>\n",
    "    <li><i>ranges</i> – Array of the dims arrays of the histogram bin boundaries in each dimension. When the histogram is uniform ( uniform =true), then for each dimension i it is enough to specify the lower (inclusive) boundary $L_0$ of the 0-th histogram bin and the upper (exclusive) boundary $U_{\\texttt{histSize}[i]-1}$ for the last histogram bin histSize[i]-1 . That is, in case of a uniform histogram each of ranges[i] is an array of 2 elements. When the histogram is not uniform ( uniform=false ), then each of ranges[i] contains histSize[i]+1 elements: $L_0, U_0=L_1, U_1=L_2, ..., U_{\\texttt{histSize[i]}-2}=L_{\\texttt{histSize[i]}-1}, U_{\\texttt{histSize[i]}-1}$ . The array elements, that are not between $L_0$ and $U_{\\texttt{histSize[i]}-1}$ , are not counted in the histogram. </li>\n",
    "    <li><i>hist</i> – Output histogram, which is a dense or sparse dims -dimensional array.</li>\n",
    "    <li><i>accumalate</i> – Accumulation flag. If it is set, the histogram is not cleared in the beginning when it is allocated. This feature enables you to compute a single histogram from several sets of arrays, or to update the histogram in time.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mask for our image\n",
    "mask = np.zeros(retina.shape, dtype='uint8')\n",
    "\n",
    "centerX = mask.shape[0] // 2\n",
    "centerY = mask.shape[1] // 2\n",
    "\n",
    "cv2.circle(mask, (centerX, centerY), round(centerY * .95), 255, cv2.FILLED)\n",
    "\n",
    "hist = cv2.calcHist([retina], [0], None, [256], [0, 256])\n",
    "hist_mask = cv2.calcHist([retina], [0], mask, [256], [0, 256])\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Retina\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(retina, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Histogram of the Retina without mask\")\n",
    "plt.xlabel(\"Bins\")\n",
    "plt.ylabel(\"# of Pixels\")\n",
    "plt.plot(hist)\n",
    "plt.xlim([-10, 256])\n",
    "plt.ylim([0, 10000])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Histogram of the Retina with mask\")\n",
    "plt.xlabel(\"Bins\")\n",
    "plt.ylabel(\"# of Pixels\")\n",
    "plt.plot(hist_mask)\n",
    "plt.xlim([-10, 256])\n",
    "plt.ylim([0, 10000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) Histogram equalization\n",
    "\n",
    "The histogram equalization improves the contrast of an image by ```stretching``` the distribution of pixels.\n",
    "\n",
    "The OpenCV has the following function to help us: \n",
    "\n",
    "<center>\n",
    "    <strong>cv2.equalizeHist(src[, dst]) → dst</strong><br />\n",
    "</center>\n",
    "\n",
    "where:\n",
    "\n",
    "<ul>\n",
    "    <li><i>src</i> – Source 8-bit single channel image.</li>\n",
    "    <li><i>dst</i> – Destination image of the same size and type as src.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized = cv2.equalizeHist(retina)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Retina\")\n",
    "plt.imshow(retina, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Retina after histogram equalization\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(equalized, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "histAfter = cv2.calcHist([equalized], [0], None, [256], [0, 256])\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Histogram of the Retina after equalization\")\n",
    "plt.xlabel(\"Bins\")\n",
    "plt.ylabel(\"# of Pixels\")\n",
    "plt.plot(histAfter)\n",
    "plt.xlim([-10, 256])\n",
    "plt.ylim([0, 10000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Thresholding\n",
    "\n",
    "Basically, this technique is used when you wish to binarize an image. Normally, we performs the thresholding to focus on objects or areas of particular interest in an image, and here we will see some kinds of binarizations.\n",
    "\n",
    "## 5.1) Simple Thresholding\n",
    "\n",
    "The simple thresholding uses the human intervention, who informs the pixels which will receive value 0 and 255. With OpenCV, we can do it with function *threshold*. \n",
    "\n",
    "<center>\n",
    "    <strong>cv2.threshold(src, thresh, maxval, type[, dst]) → retval, dst</strong><br />\n",
    "</center>\n",
    "\n",
    "where:\n",
    "\n",
    "<ul>\n",
    "    <li><i>src</i> – Input array (single-channel, 8-bit or 32-bit floating point).</li>\n",
    "    <li><i>thresh</i> – Threshold value.</li>\n",
    "    <li><i>maxval</i> – Maximum value to use with the THRESH_BINARY and THRESH_BINARY_INV thresholding types.</li>\n",
    "    <li><i>type</i> – THRESH_BINARY, THRESH_BINARY_INV, THRESH_TRUNC, THRESH_TOZERO, THRESH_TOZERO_INV.</li>\n",
    "    <li><i>dst</i> – Output array of the same size and type as src.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, binarized = cv2.threshold(retina, 60, 255, cv2.THRESH_BINARY)\n",
    "_, binarized_after = cv2.threshold(equalized, 155, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "_, binarized_inv = cv2.threshold(retina, 60, 255, cv2.THRESH_BINARY_INV)\n",
    "_, binarized_after_inv = cv2.threshold(equalized, 155, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Retina\")\n",
    "plt.imshow(retina, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Retina after binarization\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(binarized, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Equalized Retina after binarization\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(binarized_after, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Retina after inverted binarization\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(binarized_inv, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Equalized Retina after inverted binarization\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(binarized_after_inv, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2) Adaptative thresholding\n",
    "\n",
    "To avoid the human intervention on which pixel should receives value 0 or 255, we can use an adaptative thresholding, that considers small neighbors of pixels and then finds an optimal threshold value T for each neighbor.\n",
    "\n",
    "<center>\n",
    "    <strong>cv.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst]) → dst</strong><br />\n",
    "</center>\n",
    "\n",
    "where:\n",
    "\n",
    "<ul>\n",
    "    <li><i>src</i> – Source 8-bit single-channel image.</li>\n",
    "    <li><i>maxValue</i> – \tNon-zero value assigned to the pixels for which the condition is satisfied.</li>\n",
    "    <li><i>adaptiveMethod</i> – ADAPTIVE_THRESH_MEAN_C, ADAPTIVE_THRESH_GAUSSIAN_C. The BORDER_REPLICATE | BORDER_ISOLATED is used to process boundaries. </li>\n",
    "    <li><i>thresholdType</i> – Same of simple threshold.</li>\n",
    "    <li><i>blockSize</i> – Size of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7, and so on.</li>\n",
    "    <li><i>C</i> – Constant subtracted from the mean or weighted mean (see the details below). Normally, it is positive but may be zero or negative as well.</li>\n",
    "    <li><i>dst</i> – Destination image of the same size and the same type as src.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptative_mean = cv2.adaptiveThreshold(retina, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, 4)\n",
    "adaptative_gaussian = cv2.adaptiveThreshold(retina, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 4)\n",
    "\n",
    "adaptative_mean_inv = cv2.adaptiveThreshold(retina, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 15, 4)\n",
    "adaptative_gaussian_inv = cv2.adaptiveThreshold(retina, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 4)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Retina\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(retina, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Retina after adaptative threshold with mean method\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(adaptative_mean, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Retina after adaptative threshold with Gaussian method\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(adaptative_gaussian, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Retina after adaptative threshold with mean method and inverted type\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(adaptative_mean_inv, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Retina after adaptative threshold with Gaussian method and inverted type\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(adaptative_gaussian_inv, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Besides these functions, there are other methods like Otsu’s Binarization, if you want get to know this method and other things, check this reference [6].\n",
    "\n",
    "# References\n",
    "\n",
    "[1] Rosebrock, A., 2017. Deep Learning for Computer Vision with Python. 1st ed. https://www.pyimagesearch.com: PyImageSearch.\n",
    "\n",
    "[2] Leonardo Araujo dos Santos. 2018. Convolution · Artificial Inteligence. [ONLINE] Available at: https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/convolution.html. [Accessed 01 May 2018].\n",
    "\n",
    "[3] Explained Visually. 2018. Image Kernels explained visually. [ONLINE] Available at: http://setosa.io/ev/image-kernels/. [Accessed 01 May 2018].\n",
    "\n",
    "[4] Image Filtering — OpenCV 2.4.13.6 documentation. 2018. Image Filtering — OpenCV 2.4.13.6 documentation. [ONLINE] Available at: https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html. [Accessed 02 May 2018]. \n",
    "\n",
    "[5] Rosebrock, A., 2014. Practical Python and OpenCV: An Introductory, Example Driven Guide to Image Processing and Computer Vision. 1st ed. PyImageSearch.com.\n",
    "\n",
    "[6] OpenCV: Image Thresholding. 2018. OpenCV: Image Thresholding. [ONLINE] Available at: https://docs.opencv.org/3.4.0/d7/d4d/tutorial_py_thresholding.html. [Accessed 04 May 2018]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
